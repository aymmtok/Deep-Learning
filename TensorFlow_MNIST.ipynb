{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds.load(name, with_info, as_supervised) - loads a dataset from TensorFlow datasets \n",
    "# as_supervised=True - loads the data in a 2-tuple structure[input, target]\n",
    "# with_info = True - provides a tuple containing info about version, features, # of datasets\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "# numbber of train sets are 600000 out of 700000\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# casts a variable into a given data type\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "\n",
    "## scale inputs between 0 and 1\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255. \n",
    "    return image, label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "# scale test data\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "\n",
    "## shuffle the data\n",
    "# we cant shuffle a large data at once\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "# batch size = 1 - SGD\n",
    "# batch size = number of samples - (single batch) GD\n",
    "# 1 < batch size < # samples - mini-batch GD\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# dataset.batch(batch_size) - combines the consecutive elements of a dataset into batches\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "# iter() creates an object which can be iterated one element at a time(in a loop)\n",
    "# next() loads the next element of an iterable object\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "# if we increase the hidden layer size, the accuracy will increase\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# tf.keras.Sequential() function that is laying down the model\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # tf.keras.layers.Flatten(original shape) transforms a tensor into a vector\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    # Dense(output size) takes the inputs, provided to the model and calculates \n",
    "    # the dot product of the inputs and the weights and adds the bias.\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    # Include 10 hidden layers, then accuracy will increase\n",
    "    \n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',# 2 other types of crossentropy\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 70s - loss: 0.4339 - accuracy: 0.8772 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 75s - loss: 0.1903 - accuracy: 0.9450 - val_loss: 0.1614 - val_accuracy: 0.9538\n",
      "Epoch 3/5\n",
      "540/540 - 76s - loss: 0.1414 - accuracy: 0.9586 - val_loss: 0.1389 - val_accuracy: 0.9582\n",
      "Epoch 4/5\n",
      "540/540 - 78s - loss: 0.1170 - accuracy: 0.9648 - val_loss: 0.1206 - val_accuracy: 0.9647\n",
      "Epoch 5/5\n",
      "540/540 - 80s - loss: 0.0982 - accuracy: 0.9696 - val_loss: 0.1019 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x637392810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, \n",
    "        validation_targets), validation_steps = VALIDATION_STEPS, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To achieve 98.5%+ accuracy\n",
    "<li> create 10 hidden layers\n",
    "<li> hidden_layer_size = 5000\n",
    "<li> batch_size = 150\n",
    "<li> NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 0.1084 - accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "# model.evaluate()-returns the loss value and metrics values for the model in test mode\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11. Test accuracy: 96.86%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0] *",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
